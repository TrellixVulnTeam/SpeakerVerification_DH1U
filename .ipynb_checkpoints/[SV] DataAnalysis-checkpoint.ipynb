{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bc18c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "window.scroll_flag = true\n",
       "window.scroll_exit = false\n",
       "window.scroll_delay = 100\n",
       "\n",
       "\n",
       "$(\".output_scroll\").each(function() {\n",
       "    $(this)[0].scrollTop = $(this)[0].scrollHeight;\n",
       "});\n",
       "\n",
       "function callScrollToBottom() {\n",
       "    setTimeout(scrollToBottom, window.scroll_delay);\n",
       "}\n",
       "\n",
       "function scrollToBottom() {\n",
       "    if (window.scroll_exit) {\n",
       "        return;\n",
       "    }\n",
       "    if (!window.scroll_flag) {\n",
       "        callScrollToBottom();\n",
       "        return;\n",
       "    };\n",
       "    \n",
       "    $(\".output_scroll\").each(function() {\n",
       "        if (!$(this).attr('scroll_checkbox')){\n",
       "            window.scroll_flag = true;\n",
       "            $(this).attr('scroll_checkbox',true);\n",
       "            var div = document.createElement('div');\n",
       "            var checkbox = document.createElement('input');\n",
       "            checkbox.type = \"checkbox\";\n",
       "            checkbox.onclick = function(){window.scroll_flag = checkbox.checked}\n",
       "            checkbox.checked = \"checked\"\n",
       "            div.append(\"Auto-Scroll-To-Bottom: \");\n",
       "            div.append(checkbox);\n",
       "            $(this).parent().before(div);\n",
       "        }\n",
       "        \n",
       "        $(this)[0].scrollTop = $(this)[0].scrollHeight;\n",
       "    });\n",
       "    callScrollToBottom();\n",
       "}\n",
       "scrollToBottom();\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "window.scroll_flag = true\n",
    "window.scroll_exit = false\n",
    "window.scroll_delay = 100\n",
    "\n",
    "\n",
    "$(\".output_scroll\").each(function() {\n",
    "    $(this)[0].scrollTop = $(this)[0].scrollHeight;\n",
    "});\n",
    "\n",
    "function callScrollToBottom() {\n",
    "    setTimeout(scrollToBottom, window.scroll_delay);\n",
    "}\n",
    "\n",
    "function scrollToBottom() {\n",
    "    if (window.scroll_exit) {\n",
    "        return;\n",
    "    }\n",
    "    if (!window.scroll_flag) {\n",
    "        callScrollToBottom();\n",
    "        return;\n",
    "    };\n",
    "    \n",
    "    $(\".output_scroll\").each(function() {\n",
    "        if (!$(this).attr('scroll_checkbox')){\n",
    "            window.scroll_flag = true;\n",
    "            $(this).attr('scroll_checkbox',true);\n",
    "            var div = document.createElement('div');\n",
    "            var checkbox = document.createElement('input');\n",
    "            checkbox.type = \"checkbox\";\n",
    "            checkbox.onclick = function(){window.scroll_flag = checkbox.checked}\n",
    "            checkbox.checked = \"checked\"\n",
    "            div.append(\"Auto-Scroll-To-Bottom: \");\n",
    "            div.append(checkbox);\n",
    "            $(this).parent().before(div);\n",
    "        }\n",
    "        \n",
    "        $(this)[0].scrollTop = $(this)[0].scrollHeight;\n",
    "    });\n",
    "    callScrollToBottom();\n",
    "}\n",
    "scrollToBottom();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6a2732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "from torchaudio.transforms import Vad\n",
    "\n",
    "import wave\n",
    "import librosa\n",
    "import contextlib\n",
    "\n",
    "import random\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "import subprocess\n",
    "from pydub import AudioSegment\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c6980a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 12\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.rc('grid', linestyle=\"-\", color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bb475d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from processing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e0e7d7",
   "metadata": {},
   "source": [
    "## Audio utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0798c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spec(filepath):\n",
    "    samplingFrequency, signalData = wavfile.read(filepath)\n",
    "    \n",
    "    # Plot the signal read from wav file\n",
    "    if len(signalData.shape) == 1:\n",
    "        # single channel\n",
    "        plt.figure(figsize=(12,8))\n",
    "#         plt.grid(visible=True, axis='both')\n",
    "        plt.subplot(211)\n",
    "\n",
    "        plt.title('Spectrogram of a wav file')\n",
    "\n",
    "        plt.plot(signalData)\n",
    "        plt.xlabel('Sample')\n",
    "        plt.ylabel('Amplitude')\n",
    "\n",
    "        plt.subplot(212)\n",
    "        plt.specgram(signalData,Fs=samplingFrequency,NFFT=512)\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Frequency')\n",
    "    else:\n",
    "        signal_transpose = signalData.T\n",
    "        for i, signal in enumerate(signal_transpose):\n",
    "            print(f\"Channel {i + 1}\")\n",
    "            plt.figure()\n",
    "            plt.subplot(211)\n",
    "            plt.title('Spectrogram of a wav file')\n",
    "\n",
    "            plt.plot(signal.T)\n",
    "            plt.xlabel('Sample')\n",
    "            plt.ylabel('Amplitude')\n",
    "\n",
    "            plt.subplot(212)\n",
    "            plt.specgram(signal.T,Fs=samplingFrequency,NFFT=512)\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Frequency')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def plot_duo(path1, path2):\n",
    "    samplingFrequency1, signalData1 = wavfile.read(path1)\n",
    "    samplingFrequency2, signalData2 = wavfile.read(path2)\n",
    "    # single channel\n",
    "#     plt.figure(figsize=(20,8))\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 4))\n",
    "    axs[0, 0].plot(signalData1)\n",
    "    axs[0, 0].set_title('Ref')\n",
    "    axs[0, 0].set(xlabel='Sample', ylabel='Amplitude')\n",
    "    \n",
    "    axs[0, 1].specgram(signalData1,Fs=samplingFrequency1,NFFT=512)\n",
    "    axs[0, 1].set(xlabel='Time', ylabel='Frequency')\n",
    "    \n",
    "\n",
    "    axs[1, 0].plot(signalData2)\n",
    "    axs[1, 0].set_title('Com')\n",
    "    axs[1, 0].set(xlabel='Sample', ylabel='Amplitude')\n",
    "    \n",
    "    axs[1, 1].specgram(signalData2,Fs=samplingFrequency2,NFFT=512)\n",
    "    axs[1, 1].set(xlabel='Time', ylabel='Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_duration_file(fn_audio):\n",
    "    with contextlib.closing(wave.open(str(fn_audio),'r')) as f:\n",
    "        frames = f.getnframes()\n",
    "        rate = f.getframerate()\n",
    "        duration = frames / float(rate)\n",
    "    return duration\n",
    "\n",
    "def get_audio_overview(fn_audio):\n",
    "    ob =  sf.SoundFile(fn_audio)\n",
    "    return ob.subtype, ob.samplerate, ob.channels\n",
    "\n",
    "\n",
    "def get_amplitute_file(path):\n",
    "    sr, data = wavfile.read(path)\n",
    "#     bit_depth = int(get_infor_file(path)[0].split('_')[-1])\n",
    "    bit_depth = 16\n",
    "    db = 20 * np.log10(max(abs(data))/(2**(bit_depth - 1) - 1))\n",
    "    return sr, min(data), max(data), db\n",
    "\n",
    "def get_duration_folder(folder):\n",
    "    total_length = 0\n",
    "    for audio in glob.glob(f\"{folder}/*.wav\"):\n",
    "        try:\n",
    "            total_length += get_duration_file(audio)\n",
    "        except:\n",
    "            print(\"error in \",audio)\n",
    "    return total_length\n",
    "\n",
    "def get_size_file(fname):\n",
    "    return Path(fname).stat().st_size\n",
    "\n",
    "def get_size_folder(folder):\n",
    "    return sum([float(get_size_file(f)) for f in glob.glob(f\"{folder}/*\")])\n",
    "\n",
    "def get_audio_stats(filename):\n",
    "    cmd = ['ffmpeg', '-i', filename, '-map', '0:a', '-af', 'astats', '-f', 'null', '-']\n",
    "#     cmd = ['ffprobe', filename]\n",
    "    out = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE).stderr\n",
    "    output_lines = [line.strip() for line in out.decode('utf-8').split('\\n')]\n",
    "    return output_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379fc662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_and_plot_audio(path, plot=False):\n",
    "    audio = ipd.Audio(path, autoplay=True) \n",
    "    ipd.display(audio)\n",
    "    if plot:\n",
    "        plot_spec(path)\n",
    "\n",
    "def stream_and_plot_in_class(folder, plot=False, delay=0.5, fmat='.wav'):\n",
    "    audio_in_folder = glob.glob(f\"{folder}/*{fmat}\")\n",
    "    for i, f in enumerate(audio_in_folder):\n",
    "        path  = str(Path(f))\n",
    "        print(f\"[{i + 1}/{len(audio_in_folder)}] {path}\", end=' ')\n",
    "\n",
    "        stream_and_plot_audio(path, plot=plot)\n",
    "\n",
    "        duration = librosa.get_duration(filename=path)\n",
    "\n",
    "        time.sleep(duration + delay)\n",
    "        \n",
    "def stream_and_plot_in_root(root, plot=False, start_index=0):\n",
    "    folders = Path(root).glob('*')\n",
    "#     nfiles = [len(os.listdir(str(x))) for x in folders]\n",
    "    \n",
    "    for index, folder in enumerate(list(folders)[start_index:]):\n",
    "        print('id:', index + start_index, folder.name)\n",
    "        \n",
    "        stream_and_plot_in_class(str(folder), plot=plot)\n",
    "        time.sleep(1.0)\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "def compare2files(file1, file2, plot=False, stream=False):\n",
    "    if plot:\n",
    "        plot_duo(file1, file2)\n",
    "        \n",
    "    if stream:\n",
    "        stream_and_plot_audio(file1, plot=False)\n",
    "        duration = librosa.get_duration(filename=file1)\n",
    "        time.sleep(duration + 0.5)\n",
    "\n",
    "        stream_and_plot_audio(file2, plot=False)\n",
    "        duration = librosa.get_duration(filename=file2)\n",
    "        time.sleep(duration + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a012f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import noisereduce as nr\n",
    "# load data\n",
    "def remove_noise(path):\n",
    "    rate, data = wavfile.read(path)\n",
    "    # perform noise reduction\n",
    "    reduced_noise = nr.reduce_noise(y=data, sr=rate, n_fft=512, prop_decrease=0.99)\n",
    "    filename = f\"{path.replace('.wav', '')}_rm_noise.wav\"\n",
    "    wavfile.write(filename, rate, reduced_noise)\n",
    "    return True\n",
    "\n",
    "def change_volume(path=None, dB=6, overwrite=True):\n",
    "    segment = AudioSegment.from_file(path)\n",
    "    segment += dB\n",
    "    if overwrite:\n",
    "        path = path\n",
    "    else:\n",
    "        path = path.replace('.wav', '') + f'_{dB}' +'.wav'\n",
    "    segment.export(path, format='wav')\n",
    "    print(f'Export to {path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b2f06d",
   "metadata": {},
   "source": [
    "## Stream and visualize audio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42779c4",
   "metadata": {},
   "source": [
    "#### File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"log_service/audio_v2/346165056/346165056-20220310-173805_20220310_103846_com_0.wav\"\n",
    "stream_and_plot_audio(path, plot=True)\n",
    "# !ffprobe \"dataset/spoof/2835449000/2835449000_23_zoneB_rm_noise.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fa8a15",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "com = f\"log_service/audio/20220208_101958_com_vad_1.wav\"\n",
    "\n",
    "ref = f\"log_service/audio/20220208_101947_ref_vad_0.wav\"\n",
    "\n",
    "compare2files(ref, com, plot=True, stream=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e440dbe",
   "metadata": {},
   "source": [
    "#### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dcb73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/test_callbot_raw/infor.csv\", 'w') as wf:\n",
    "    for i, folder in enumerate(Path(\"dataset/test_callbot_raw/namdp5/\").glob('*')):\n",
    "#         wf.write(f\"{i},{folder.name},{len(os.listdir(str(folder)))}\\n\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf2beb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stream_and_plot_in_class(\"log_service/audio_v2/912582757/\", plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a172bc",
   "metadata": {},
   "source": [
    "#### Root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87264ae",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "stream_and_plot_in_root(\"dataset/test_callbot_raw/namdp5/\", start_index=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f4f6c4",
   "metadata": {},
   "source": [
    "#### stats of audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8314c479",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!ffmpeg -i \"dataset/test_callbot_raw/namdp5/349238241/349238241-20220204-101127-in_1.wav\" -map 0:a -af astats -f null -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96327fe2",
   "metadata": {},
   "source": [
    "## Perform vad on long file(>10s of duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98486f9",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "path = f\"log_service/audio/20220208_101947_ref.wav\"\n",
    "write = False\n",
    "segments = vad_tool.VAD(win_length=300, frame_duration=30).detect(path, write=write, show=True)\n",
    "print(len(segments))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed443bf2",
   "metadata": {},
   "source": [
    "# Visualize by graph dataset, plot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f52e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = \"dataset/train\"\n",
    "filenames = glob.glob(f\"{origin}/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c699112a",
   "metadata": {},
   "source": [
    "### number of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a463833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so luong files moi nguoi\n",
    "no_of_files = []\n",
    "for f in tqdm(filenames):\n",
    "    if len(os.listdir(f)) == 0:\n",
    "        print(f)\n",
    "    no_of_files.append(len(os.listdir(f)))\n",
    "plt.figure(figsize=(24, 8))\n",
    "plt.bar(filenames, no_of_files), plt.ylabel('number of files'), plt.xticks([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c00a0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames[np.argmax(no_of_files)], filenames[np.argmin(no_of_files)], sum(no_of_files), max(no_of_files), min(no_of_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac26928",
   "metadata": {},
   "source": [
    "### Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01256fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration\n",
    "durations = []\n",
    "for fn in tqdm(filenames):\n",
    "    length = get_duration_folder(fn)\n",
    "    durations.append(length)\n",
    "plt.figure(figsize=(24, 8))\n",
    "plt.bar(filenames, durations), plt.ylabel('durations'), plt.xticks([]), plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61392914",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(durations), np.argmax(durations), sum(durations), max(durations), min(durations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adad42b5",
   "metadata": {},
   "source": [
    "### average duration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734dafd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat do thoi gian / 1 audio tren moi nguoi\n",
    "import numpy as np\n",
    "no_of_files = np.array(no_of_files)\n",
    "durations = np.array(durations)\n",
    "avg_durations = np.divide(durations, no_of_files)\n",
    "plt.figure(figsize=(24, 8))\n",
    "plt.bar(filenames, avg_durations), plt.ylabel('avg_durations'), plt.xticks([]), plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7333fe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_durations.mean(), np.argmax(avg_durations), max(avg_durations), min(avg_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb402b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(avg_durations[(avg_durations >= 1.5).nonzero()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62faea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  index: 0'Duration', 1'Size(MB)', 2'Min level', 3'Max level', \n",
    "#         4'Min difference', 5'Max difference', 6'Mean difference', 7'RMS difference', \n",
    "#         8'Peak level dB', 9'RMS level dB', 10'RMS peak dB', 11'RMS trough dB', \n",
    "#         12'Crest factor', 13'Flat factor', 14'Peak count',\n",
    "#         15'Noise floor dB', 16'Noise floor count', 17'Dynamic range', \n",
    "#         18'Zero crossings', 19'Zero crossings rate', 20'Error rate',\n",
    "\n",
    "audio_full_infor = {}\n",
    "detail_dir = Path('dataset/train_callbot/details/')\n",
    "csv_s = detail_dir.glob('*.csv')\n",
    "\n",
    "for f in tqdm(csv_s):\n",
    "    audio_full_infor[f.name.replace('.csv', '')] = []\n",
    "    \n",
    "    with open(f, 'r', newline='') as rf:\n",
    "        spamreader = csv.reader(rf, delimiter=',')\n",
    "        next(spamreader, None)\n",
    "        for row in spamreader:\n",
    "            row_n = []\n",
    "            for e in row:\n",
    "                try:\n",
    "                    row_n.append(float(e.strip()))\n",
    "                except:\n",
    "                    pass\n",
    "            audio_full_infor[f.name.replace('.csv', '')].append(np.asanyarray(row_n))\n",
    "            \n",
    "    audio_full_infor[f.name.replace('.csv', '')] = np.asanyarray(audio_full_infor[f.name.replace('.csv', '')])\n",
    "            \n",
    "list(audio_full_infor.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c6c4a5",
   "metadata": {},
   "source": [
    "index: <br/>\n",
    "0'Duration', 1'Size(MB)', 2'Min level', 3'Max level', <br/>\n",
    "4'Min difference', 5'Max difference', 6'Mean difference', 7'RMS difference', <br/>\n",
    "8'Peak level dB', 9'RMS level dB', 10'RMS peak dB', 11'RMS trough dB', <br/>\n",
    "12'Crest factor', 13'Flat factor', 14'Peak count', <br/>\n",
    "15'Noise floor dB', 16'Noise floor count', 17'Dynamic range', <br/>\n",
    "18'Zero crossings', 19'Zero crossings rate', 20'Error rate', <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1f2f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum up informations\n",
    "categories = ['Avg_duration', 'Min_duration', 'Max_duration', \n",
    "              'Avg_peakdB', 'Min_peakdB', 'Max_peakdB',\n",
    "              'Avg_noisedB', 'Min_noisedB', 'Max_noisedB',\n",
    "              '#valid files', '%valid']\n",
    "\n",
    "# writefile = 'dataset/details_callbot.csv'\n",
    "with open(writefile, 'w', newline='') as wf:\n",
    "    spamwriter = csv.writer(wf, delimiter=',')\n",
    "    spamwriter.writerow(categories)\n",
    "    \n",
    "    for k, v in tqdm(audio_full_infor.items()):\n",
    "        avg_dur, min_dur, max_dur = np.mean(v[:,0]), min(v[:,0]), max(v[:,0])\n",
    "        avg_db, min_db, max_db = np.mean(v[:,8]), min(v[:,8]), max(v[:,8])\n",
    "        avg_noisedb, min_noisedb, max_noisedb =  np.mean(v[:,15]), min(v[:,15]), max(v[:,15])\n",
    "        # error rate add here#\n",
    "        f_invalid = read_blacklist(id=k,\n",
    "                                 duration_limit=1.0, \n",
    "                                 dB_limit=-16, \n",
    "                                 error_limit=0, \n",
    "                                 noise_limit=-10, \n",
    "                                 details_dir=\"dataset/train_callbot/details/\" )\n",
    "        n_valid = len(v) - len(f_invalid) if f_invalid else len(v)\n",
    "        p_valid = n_valid / len(v)\n",
    "        \n",
    "        row =  [avg_dur, min_dur, max_dur,\n",
    "               avg_db, min_db, max_db,\n",
    "               avg_noisedb, min_noisedb, max_noisedb,\n",
    "               n_valid, p_valid]\n",
    "#         spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a1b90e",
   "metadata": {},
   "source": [
    "## Filtering DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2694ac6",
   "metadata": {},
   "source": [
    "Check the inequality of dataset and print out details, return number of files greater ans lower than threshold(35 files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a02a44",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with open(\"Imposter_v2.txt\", 'r') as rf:\n",
    "    lines = [line.strip().replace('\\n', '') for line in rf.readlines()]\n",
    "\n",
    "invalid_class = list(''.join(x.split(':')[1:]).strip() for x in filter(lambda x: True if ':' in x else False, lines))\n",
    "invalid_files = list(''.join(x.split('-')[1:]).strip() for x in filter(lambda x: True if '-' in x else False, lines))\n",
    "# len(invalid_files), len(invalid_class), invalid_class[-1], glob.glob(\"dataset/train/*\").index(invalid_class[-1])\n",
    "\n",
    "invalid_details = {}\n",
    "for line in tqdm(lines):\n",
    "    if ':' in line:\n",
    "        k = ''.join(line.split(':')[1:]).strip()\n",
    "        if k not in invalid_details:\n",
    "            invalid_details[k] = {}\n",
    "    elif '.wav' in line:\n",
    "        fp = ''.join(line.split(' - ')[1:]).strip()\n",
    "        n = line.split('-')[0].strip().replace('[', '').replace(']', '').split('/')\n",
    "        rate = float(n[0])/float(n[1])\n",
    "        \n",
    "        k = list(invalid_details.keys())[-1]\n",
    "        \n",
    "        invalid_details[k][fp] = rate\n",
    "\n",
    "list(invalid_details.items())[:10]\n",
    "# invalid_cla                                                                                                                                     ss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c48394",
   "metadata": {},
   "source": [
    "### Train val generate simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c72bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing.dataset import read_blacklist, check_valid_audio\n",
    "def generate_lists(raw_dataset,num_spks, split_ratio,\n",
    "                   details_dir=None,\n",
    "                   duration_limit=1.0,\n",
    "                   dB_limit=-10,\n",
    "                   error_limit=0.5,\n",
    "                   noise_limit=-16, \n",
    "                   lower_num=10, upper_num = 40,\n",
    "                   gen_files=False, seperate_files=False):\n",
    "    \"\"\"\n",
    "    Generate train test lists for zalo data\n",
    "    \"\"\"\n",
    "    valid_spks = []\n",
    "    invalid_spks = []\n",
    "    \n",
    "    root = Path(raw_dataset)\n",
    "    classpaths = [d for d in root.iterdir() if d.is_dir()]\n",
    "    classpaths.sort()\n",
    "    \n",
    "    if 0 < num_spks < len(classpaths) + 1:\n",
    "        classpaths = classpaths[:num_spks]\n",
    "    elif num_spks == -1:\n",
    "        pass\n",
    "    else:\n",
    "        raise \"Invalid number of speakers\"\n",
    "\n",
    "    print('Generate dataset metadata files, total:', len(classpaths))\n",
    "    \n",
    "    train_filepaths_list = []\n",
    "    val_filepaths_list = []\n",
    "            \n",
    "    for classpath in tqdm(list(classpaths)[:], desc=\"Processing:...\"):\n",
    "        filepaths = list(classpath.glob('*.wav'))\n",
    "        # filtering dataset\n",
    "        ## check duration, volumn\n",
    "#         blist = read_blacklist(str(Path(classpath).name), \n",
    "#                                duration_limit=duration_limit, \n",
    "#                                dB_limit=dB_limit, \n",
    "#                                error_limit=error_limit, \n",
    "#                                noise_limit=noise_limit,\n",
    "#                                details_dir=details_dir)\n",
    "        blist = None\n",
    "\n",
    "        if blist is not None:\n",
    "            filepaths = list(set(filepaths).difference(set(blist)))\n",
    "\n",
    "        ## check duration, sr\n",
    "        filepaths = check_valid_audio(filepaths, duration_limit, 8000)\n",
    "\n",
    "        ## checknumber of files\n",
    "        if lower_num:\n",
    "            if len(filepaths) < lower_num:\n",
    "                continue\n",
    "                \n",
    "        if upper_num > 0:\n",
    "            if len(filepaths) >= upper_num:\n",
    "                filepaths = filepaths[:upper_num]\n",
    "                \n",
    "        if len(filepaths) == 0:\n",
    "            continue\n",
    "                    \n",
    "        valid_spks.append(str(Path(classpath)))\n",
    "        \n",
    "        random.shuffle(filepaths)        \n",
    "        \n",
    "        # val\n",
    "        val_num = 3  # 3 utterances per speaker for val\n",
    "\n",
    "        if split_ratio > 0:\n",
    "            val_num = int(split_ratio * len(filepaths))\n",
    "\n",
    "        val_filepaths = random.sample(filepaths, val_num)\n",
    "        \n",
    "        train_filepaths = filepaths if split_ratio == -1 else list(set(filepaths) - set(val_filepaths))\n",
    "        \n",
    "        # write train file\n",
    "        \n",
    "        for train_filepath in train_filepaths:\n",
    "            label = str(train_filepath.parent.stem.split('-')[0])\n",
    "            train_filepaths_list.append(f\"{label} {str(train_filepath)}\\n\")\n",
    "\n",
    "        val_filepaths_list.append(val_filepaths)\n",
    "                \n",
    "    # gen val \n",
    "    val_pairs = []\n",
    "    for val_filepaths in val_filepaths_list:\n",
    "        for i in range(len(val_filepaths) - 1):\n",
    "            for j in range(i + 1, len(val_filepaths)):\n",
    "                label = '1'\n",
    "                positive_pair = label + ' ' + str(val_filepaths[i]) + ' ' + str(val_filepaths[j]) + '\\n'\n",
    "                val_pairs.append(positive_pair)\n",
    "    \n",
    "                label = '0'\n",
    "                while True:\n",
    "                    x = random.randint(0, len(val_filepaths_list) - 1)\n",
    "                    if not val_filepaths_list[x]:\n",
    "                        continue\n",
    "                    if val_filepaths_list[x][0].parent.stem != val_filepaths[i].parent.stem:\n",
    "                        break\n",
    "                        \n",
    "                y = random.randint(0, len(val_filepaths_list[x]) - 1)\n",
    "                negative_pair = label + ' ' + str(val_filepaths[i]) + ' ' + str(val_filepaths_list[x][y]) + '\\n'\n",
    "                val_pairs.append(negative_pair)\n",
    "                \n",
    "                \n",
    "    if gen_files:\n",
    "        with open(Path(root.parent.parent, f'metadata/train_{root.parent.name}.txt'), 'w') as wf:\n",
    "            random.shuffle(train_filepaths_list) \n",
    "            wf.writelines(train_filepaths_list)\n",
    "        with open(Path(root.parent.parent, f'metadata/val_{root.parent.name}.txt'), 'w') as wf:\n",
    "            random.shuffle(val_pairs) \n",
    "            wf.writelines(val_pairs)\n",
    "            \n",
    "    if seperate_files:\n",
    "#         if os.path.isdir('dataset/valid_data'):\n",
    "#             subprocess.call('rm -r dataset/valid_data', shell=True)\n",
    "#             os.makedirs('dataset/valid_data', exist_ok=True)\n",
    "        \n",
    "        for spk_id in tqdm(valid_spks):\n",
    "            if os.path.isdir(spk_id):\n",
    "                subprocess.call(f'cp -R {spk_id} dataset/train_data/wav/', shell=True)\n",
    "            \n",
    "            \n",
    "\n",
    "    print(\"Valid speakers:\", len(valid_spks))\n",
    "    print(\"Valid audio files:\", len(train_filepaths_list))\n",
    "    print(\"Validation pairs:\", len(val_pairs))\n",
    "\n",
    "    return valid_spks, invalid_spks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df10039a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_spks, invalid_spks = generate_lists(raw_dataset='dataset/train_data/cskh_old_unlabel/wav/', \n",
    "                                          num_spks=-1, split_ratio=1.0, \n",
    "                                          duration_limit=1.5,\n",
    "                                          dB_limit=-20,\n",
    "                                          error_limit=0.5,\n",
    "                                          noise_limit=-0,\n",
    "                                          lower_num=0, upper_num = 30,\n",
    "                                          gen_files = True, seperate_files=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea2054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge 2 sets\n",
    "with open('dataset/train_data/metadata/train_cskh_oslb.txt', 'r') as rf:\n",
    "    lines_1 = rf.readlines()\n",
    "with open('dataset/train_data/metadata/train_cskh.txt', 'r') as rf:\n",
    "    lines_2 = rf.readlines()\n",
    "with open('dataset/train_data/metadata/train_callbot_raw.txt', 'r') as rf:\n",
    "    lines_3 = rf.readlines()\n",
    "    \n",
    "lines = lines_1 + lines_2 + lines_3\n",
    "\n",
    "with open('dataset/train_data/metadata/train_combined_50.txt', 'w') as wf:\n",
    "    wf.writelines(lines)\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5b1f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "5258 + 1955 + 511 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8841ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "1640 + 5772 + 13713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdced56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >=30 utts >=2.0 s\n",
    "479 + 2032 + 4377"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1973b15",
   "metadata": {},
   "source": [
    "#### Write public and private test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a2458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_spks = glob.glob('dataset/test_data/test_cskh_oslb/wav/*')\n",
    "\n",
    "for spkID in test_spks:\n",
    "    if len(str(Path(spkID).name)) >=10:\n",
    "#         subprocess.call(f'rm -r {spkID}', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836e26f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source  = 'dataset/test_data/test_cskh_oslb/wav/'\n",
    "\n",
    "import itertools    \n",
    "def all_pairs(lst):\n",
    "    return list(itertools.combinations(lst, 2))\n",
    "\n",
    "folders = Path(source).glob('*/')\n",
    "data = []\n",
    "for folder in folders:\n",
    "    f_lst = folder.glob('*.wav')\n",
    "\n",
    "    data.extend([f\"{folder.name} {path}\" for path in f_lst])\n",
    "\n",
    "pairs = all_pairs(data)\n",
    "lines_truth = []\n",
    "lines_test = []\n",
    "\n",
    "for pair in pairs:\n",
    "    label1 , path1 = pair[0].split(' ')\n",
    "    label2 , path2 = pair[1].split(' ')\n",
    "    lines_test.append(f\"{path1},{path2}\\n\")\n",
    "    lines_truth.append(f\"{int(label1==label2)} {path1} {path2}\\n\")\n",
    "    \n",
    "with open(f'dataset/test_data/test_cskh_oslb/test_cskh_oslb_truth.txt' , 'w') as wf:\n",
    "    wf.writelines(lines_truth)\n",
    "    \n",
    "with open(Path(f'dataset/test_data/test_cskh_oslb/test_cskh_oslb.txt'), 'w') as wf:\n",
    "    wf.write(f\"audio_1,audio_2\\n\")\n",
    "    wf.writelines(lines_test)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9c221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/test_callbot/valid_speaker/private_test_cb_truth.txt\", 'r') as rf:\n",
    "    pairs = [x.replace('\\n', '') for x in rf.readlines()]\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb23dbce",
   "metadata": {},
   "source": [
    "## Draft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930f9699",
   "metadata": {},
   "source": [
    "generate test files from log audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c782f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/test_data/test_cskh_oslb/test_spkID.txt', 'w') as wf:\n",
    "    for spkID in os.listdir('dataset/test_data/test_cskh_oslb/wav/'):\n",
    "        wf.write(spkID + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f83b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def all_pairs(lst):\n",
    "    return list(itertools.combinations(lst, 2))\n",
    "\n",
    "    \n",
    "list_test_ref = glob.glob(f'log_service/check_log_combine/ref/auth/*/*.wav')\n",
    "list_test_com = glob.glob(f'log_service/check_log_combine/com/auth/*/*.wav')\n",
    "\n",
    "list_test = list(set(list_test_ref + list_test_com))\n",
    "print(len(list_test))\n",
    "\n",
    "pairs = all_pairs(list_test)\n",
    "print(len(pairs))\n",
    "\n",
    "lines = []\n",
    "lines_truth = []\n",
    "counts_label = [0, 0]\n",
    "for pair in tqdm(pairs):\n",
    "    label1 = os.path.split(pair[0])[-1].split('.')[0].split('-')[0].replace('com_', '')\n",
    "    label2 = os.path.split(pair[1])[-1].split('.')[0].split('-')[0].replace('com_', '')\n",
    "\n",
    "    lines_truth.append(f\"{int(label2==label1)} {pair[0]} {pair[1]}\\n\")    \n",
    "    lines.append(f\"{pair[0]},{pair[1]}\\n\")\n",
    "\n",
    "    counts_label[0] += int(label2!=label1)\n",
    "    counts_label[1] += int(label2==label1)\n",
    "\n",
    "# with open(f'log_service/check_log_combine/ref_vs_com_auth_truth.txt' , 'w') as wf:\n",
    "#     wf.writelines(lines_truth)\n",
    "# with open(f'log_service/check_log_combine/ref_vs_com_auth.txt' , 'w') as wf:\n",
    "#     wf.write(\"audio1,audio2\\n\")\n",
    "#     wf.writelines(lines)\n",
    "\n",
    "print('Done')\n",
    "counts_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb934ce",
   "metadata": {},
   "source": [
    "#### Control volume of noise file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be82ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from processing.augment import *\n",
    "for noise_f in tqdm(glob.glob(\"dataset/noise_vad/noise_vad/*/*.wav\")):\n",
    "    noise_seg = AudioSegment.from_file(noise_f)\n",
    "    noise_seg_new_vol = gain_target_amplitude(noise_seg, -1)\n",
    "    noise_seg_new_vol.export(noise_f, format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211693ed",
   "metadata": {},
   "source": [
    "#### Test augment with env_corrupt type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e3254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from processing import audio_loader\n",
    "musan_path = \"dataset/augment_data/musan_split\"\n",
    "rir_path = \"dataset/augment_data/RIRS_NOISES/simulated_rirs\"\n",
    "augment_engine = audio_loader.AugmentWAV(musan_path=musan_path,\n",
    "                                         rir_path=rir_path,\n",
    "                                         max_frames=500,\n",
    "                                         sample_rate=8000,target_db=None)\n",
    "audio_file = \"dataset/train_callbot_v2/train_v2/spk0/spk0-20220205-064325-in_0.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4b99a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n 100 -r 10\n",
    "audio_file = \"dataset/train_callbot_v2/train_v2/spk0/spk0-20220205-064325-in_0.wav\"\n",
    "audio = audio_loader.loadWAV(audio_file, 500, \n",
    "                evalmode=False, \n",
    "                augment=False, \n",
    "                sample_rate=8000, \n",
    "                augment_chain=[])\n",
    "audio_raw = audio.copy()\n",
    "augtype , mode, order = None, None, None\n",
    "augtype = np.random.choice(['rev', 'noise', 'both', 'none'], p=[0.2, 0.6, 0, 0.2])\n",
    "\n",
    "\n",
    "p_base = [0.25, 0.25, 0.25, 0.25]\n",
    "if augtype == 'rev':\n",
    "    audio = augment_engine.reverberate(audio)\n",
    "elif augtype == 'noise':\n",
    "    mode = np.random.choice(['music', 'speech', 'noise', 'noise_vad'],  p=p_base)\n",
    "    audio = augment_engine.additive_noise(mode, audio)\n",
    "elif augtype == 'both':\n",
    "    # combined reverb and noise\n",
    "    order = np.random.choice(['noise_first', 'rev_first'], p=[0.5, 0.5])\n",
    "    if order == 'rev_first':\n",
    "        audio =augment_engine.reverberate(audio)\n",
    "        mode = np.random.choice(['music', 'speech', 'noise', 'noise_vad'],  p=p_base)\n",
    "        audio = augment_engine.additive_noise(mode, audio)\n",
    "    else:\n",
    "        mode = np.random.choice(['music', 'speech', 'noise', 'noise_vad'],  p=p_base)\n",
    "        audio = augment_engine.additive_noise(mode, audio)   \n",
    "        audio = augment_engine.reverberate(audio)\n",
    "else:\n",
    "    # none type means dont augment\n",
    "    pass\n",
    "print(augtype , mode, order)\n",
    "\n",
    "plt.figure(figsize=(24,8))\n",
    "plt.plot(np.squeeze(audio), color='red')\n",
    "plt.plot(np.squeeze(audio_raw), color='green')\n",
    "plt.show()\n",
    "ipd.Audio(audio, rate=8000, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b61458",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"label_for_log.csv\",\"w+\") as wf:\n",
    "    wf.write(\"class,filename,label\\n\")\n",
    "    for f in glob.glob(\"log_service/cskh_test_202203/wav_logs/*/*/*_norm.wav\"):\n",
    "        cls = f.split('/')[-2]\n",
    "        wf.write(f\"{cls}, {'/'.join(f.split('/')[-3:])}, 1\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3571e9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stream_and_plot_in_class(\"log_service/check_log_combine/com/auth/346165056/\", delay=1, fmat=\".wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b5fca",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# test set from log audios file\n",
    "data_norm = {}\n",
    "data_auth = {}\n",
    "with open(\"log_service/label_for_log.csv\", newline='') as rf:\n",
    "        spamreader = csv.reader(rf, delimiter=',')\n",
    "        next(spamreader, None)\n",
    "        for row in spamreader:\n",
    "            if row[0] not in data_norm:\n",
    "                data_norm[row[0]] = []\n",
    "            data_norm[row[0]].append([row[1].strip(), row[2]])\n",
    "            \n",
    "            if row[0] not in data_auth:\n",
    "                data_auth[row[0]] = []\n",
    "            data_auth[row[0]].append([row[1].strip().replace('_norm', ''), row[2]])\n",
    "ref_auth = {}\n",
    "ref_norm = {}\n",
    "for spk in glob.glob(\"log_service/cskh_test_202203/ref_audio/*\"):\n",
    "    audio_fs = glob.glob(spk + '/*.wav')\n",
    "    cls = spk.split('/')[-1]\n",
    "    if cls not in ref_auth:\n",
    "        ref_auth[cls] = []\n",
    "    ref_auth[cls].extend(glob.glob(os.path.join(spk, '*.wav')))\n",
    "for spk in glob.glob(\"log_service/cskh_test_202203/ref_audio_norm/*\"):\n",
    "    audio_fs = glob.glob(spk + '/*.wav')\n",
    "    cls = spk.split('/')[-1]\n",
    "    if cls not in ref_norm:\n",
    "        ref_norm[cls] = []\n",
    "    ref_norm[cls].extend(glob.glob(os.path.join(spk, '*.wav')))\n",
    "data_norm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b974f31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test file\n",
    "# # log_service/cskh_test_202203/wav_logs/wavs-2022-03-30\n",
    "for k, v in data_auth.items():\n",
    "    os.makedirs(os.path.join(f\"log_service/check_log_combine/com/auth/{k}\"), exist_ok=True)\n",
    "    for f, label in v:\n",
    "        fullpath = os.path.join(\"log_service/cskh_test_202203/wav_logs/\", f)\n",
    "        if os.path.isfile(fullpath):\n",
    "            if int(label) == 1:\n",
    "                print(f\"mv {fullpath} {fullpath.replace('/'.join(fullpath.split('/')[:4]), 'log_service/check_log_combine/com/auth')}\")\n",
    "#                 subprocess.call(f\"mv {fullpath} {fullpath.replace('/'.join(fullpath.split('/')[:4]), 'log_service/check_log_combine/com/auth')}\", shell=True)\n",
    "            \n",
    "\n",
    "for k, v in data_norm.items():\n",
    "    os.makedirs(os.path.join(f\"log_service/check_log_combine/com/norm/{k}\"), exist_ok=True)\n",
    "    for f, label in v:\n",
    "        fullpath = os.path.join(\"log_service/cskh_test_202203/wav_logs/\", f)\n",
    "        if os.path.isfile(fullpath):\n",
    "            if int(label) == 1:\n",
    "                print(f\"mv {fullpath} {fullpath.replace('/'.join(fullpath.split('/')[:4]), 'log_service/check_log_combine/com/norm')}\")\n",
    "#                 subprocess.call(f\"mv {fullpath} {fullpath.replace('/'.join(fullpath.split('/')[:4]), 'log_service/check_log_combine/com/norm')}\", shell=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8462b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_audio_distribution(root, dpi=10):\n",
    "    audio_lst_path = glob.glob(root + '/*/*wav')\n",
    "    durations = []\n",
    "    for audio in tqdm(audio_lst_path):\n",
    "        durations.append(get_duration_file(audio))\n",
    "    \n",
    "    bins = list(np.linspace(0.0, 15, num=dpi+1))\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks(np.linspace(0, 15, 11))\n",
    "    plt.xlabel('Score'), plt.ylabel('# of utterances')\n",
    "    \n",
    "    plt.hist(durations, bins, alpha=0.5, histtype='stepfilled', color='r', label='label 0')  \n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "plot_audio_distribution(\"dataset/train_callbot_v2/train_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e95617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_performance(result_file, dpi=1000):\n",
    "    lines = None\n",
    "    with open(result_file, \"r\") as rf:\n",
    "        lines = [line.replace('\\n', '') for line in rf.readlines()]\n",
    "    class_scores = [[x.split(',')[-3], x.split(',')[-1]]  for x in lines[1:]]\n",
    "    \n",
    "    class_0 = list(float(score) for _, score in filter(lambda x: True if x[0] == '0' else False, class_scores))\n",
    "    print(\"Mean, deviation and variance of class 0:\", np.mean(class_0), np.std(class_0), np.var(class_0))\n",
    "    print(\"Min and max score of class 0:\", np.min(class_0), np.max(class_0))\n",
    "    class_1 = list(float(score) for _, score in filter(lambda x: True if x[0] == '1' else False, class_scores))\n",
    "    print(\"Mean, deviation and variance of class 1:\", np.mean(class_1), np.std(class_1), np.var(class_1))\n",
    "    print(\"Min and max score of class 1:\", np.min(class_1), np.max(class_1))    \n",
    "    \n",
    "    bins = list(np.linspace(0.0, 1.0, num=dpi+1))\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks(np.linspace(0, 1, 11))\n",
    "    plt.xlabel('Score'), plt.ylabel('# of pairs')\n",
    "    \n",
    "    plt.hist(class_0, bins, alpha=0.5, histtype='stepfilled', color='r', label='label 0')\n",
    "    plt.hist(class_1, bins, alpha=0.5, histtype='stepfilled', color='g', label='label 1')    \n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f801cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = \"backup/Raw_ECAPA/ARmSoftmax/result/evaluation_results-Copy1.txt\"\n",
    "plot_classification_performance(result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dd8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test files\n",
    "valid_files = []\n",
    "with open(\"log_service/check_log_combine/files_select.txt\", 'r') as rf:\n",
    "    valid_files = list(line.replace('\\n', '').strip() for line in rf.readlines())\n",
    "    \n",
    "def filter_files(raw_set, valid_set):\n",
    "    ret = []\n",
    "    for fpath in raw_set:\n",
    "        if str(Path(fpath).name) in valid_set:\n",
    "            ret.append(fpath)\n",
    "    return ret\n",
    "\n",
    "# 3 ref  + 1 test\n",
    "# truth: label audio1 audio2\n",
    "# test: audio1,audio2\n",
    "com_dir = \"log_service/check_log_combine/com/auth\"\n",
    "ref_dir = \"log_service/check_log_combine/ref/auth\"\n",
    "\n",
    "test_pairs = []\n",
    "test_pairs_truth = []\n",
    "\n",
    "for com_id in glob.glob(com_dir + '/*'):\n",
    "    com_audio_fs = filter_files(glob.glob(com_id + '/*.wav'), valid_files)\n",
    "    com_id_ = com_id.split('/')[-1]\n",
    "    for com_audio_f in com_audio_fs:\n",
    "        for ref_id in glob.glob(ref_dir + '/*'):\n",
    "            ref_id_ = ref_id.split('/')[-1]\n",
    "            ref_audio_fs = filter_files(glob.glob(ref_id + '/*.wav'), valid_files)[:3] # 3 ref 1 com\n",
    "            test_pairs.extend([f\"{com_audio_f},{ref_audio_f}\\n\" for ref_audio_f in ref_audio_fs])\n",
    "            test_pairs_truth.extend([f\"{int(ref_id_ == com_id_)} {com_audio_f} {ref_audio_f}\\n\" for ref_audio_f in ref_audio_fs])\n",
    "\n",
    "with open(\"log_service/check_log_combine/3ref1test.txt\", \"w+\") as wf:\n",
    "    wf.write(\"audio1,audio2\\n\")\n",
    "    wf.writelines(test_pairs)\n",
    "with open(\"log_service/check_log_combine/3ref1test_truth.txt\", \"w+\") as wf:\n",
    "    wf.writelines(test_pairs_truth)\n",
    "    \n",
    "# equitable set\n",
    "audio_files = glob.glob(com_dir + '/*/*.wav') + glob.glob(ref_dir + '/*/*.wav')\n",
    "audio_files = filter_files(audio_files, valid_files)\n",
    "print(len(audio_files))\n",
    "audio_classes = {}\n",
    "for audio_file in audio_files:\n",
    "    label = audio_file.split('/')[-2]\n",
    "    if label not in audio_classes:\n",
    "        audio_classes[label] = []\n",
    "    audio_classes[label].append(audio_file)\n",
    "    \n",
    "equitable_test_pairs = []\n",
    "equitable_test_pairs_truth = []\n",
    "\n",
    "for label, list_audio in audio_classes.items():\n",
    "    # find audio in different classes\n",
    "    diff_label_list_audio_files = []\n",
    "    for diff_cls_lst in [value for key, value in audio_classes.items() if key != label]:\n",
    "        diff_label_list_audio_files.extend(diff_cls_lst)\n",
    "        \n",
    "    for i in range(len(list_audio) - 1):\n",
    "        for j in range(i + 1, len(list_audio)):\n",
    "            # pos pair\n",
    "            equitable_test_pairs.append(f\"{str(list_audio[i])},{str(list_audio[j])}\\n\")\n",
    "            equitable_test_pairs_truth.append(f\"1 {str(list_audio[i])} {str(list_audio[j])}\\n\")\n",
    "            # neg pair\n",
    "            diff_label_list_audio_file = random.choice(diff_label_list_audio_files)\n",
    "            equitable_test_pairs.append(f\"{str(list_audio[i])},{str(diff_label_list_audio_file)}\\n\")\n",
    "            equitable_test_pairs_truth.append(f\"0 {str(list_audio[i])} {str(diff_label_list_audio_file)}\\n\")            \n",
    "            \n",
    "with open(\"log_service/check_log_combine/equitable_test_v3.txt\", \"w+\") as wf:\n",
    "    wf.write(\"audio1,audio2\\n\")\n",
    "    wf.writelines(equitable_test_pairs)\n",
    "with open(\"log_service/check_log_combine/equitable_test_truth_v3.txt\", \"w+\") as wf:\n",
    "    wf.writelines(equitable_test_pairs_truth)\n",
    "\n",
    "    \n",
    "audio_files = glob.glob(com_dir + '/*/*.wav') + glob.glob(ref_dir + '/*/*.wav')\n",
    "audio_files = filter_files(audio_files, valid_files)\n",
    "all_audio_pairs = all_pairs(audio_files)\n",
    "\n",
    "all_test = []\n",
    "all_test_truth = []\n",
    "\n",
    "for pair in pairs:\n",
    "    label1 = pair[0].split('/')[-2]\n",
    "    label2 = pair[1].split('/')[-2]\n",
    "    all_test.append(f\"{pair[0]},{pair[1]}\\n\")\n",
    "    all_test_truth.append(f\"{int(label1 == label2)} {pair[0]} {pair[1]}\\n\")\n",
    "    \n",
    "with open(\"log_service/check_log_combine/all_test.txt\", \"w+\") as wf:\n",
    "    wf.write(\"audio1,audio2\\n\")\n",
    "    wf.writelines(all_test)\n",
    "with open(\"log_service/check_log_combine/all_test_truth.txt\", \"w+\") as wf:\n",
    "    wf.writelines(all_test_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546f9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from nnAudio import features\n",
    "import librosa\n",
    "import time\n",
    "\n",
    "trans1 = torchaudio.transforms.MFCC(n_mfcc= 80, \n",
    "                                    sample_rate=8000, \n",
    "                                    melkwargs={\"n_fft\": 512, \n",
    "                                               \"hop_length\": 80, \n",
    "                                               \"win_length\" :200,\n",
    "                                               'f_min':10, 'f_max':4000, \n",
    "                                               'window_fn': torch.hamming_window, \n",
    "                                               \"power\": 2, \n",
    "                                               'n_mels':80,\n",
    "                                               'norm':'slaney',\n",
    "                                               'mel_scale': 'slaney'})\n",
    "\n",
    "\n",
    "trans2 = features.mel.MFCC(sr=8000, \n",
    "                                   n_fft=512, \n",
    "                                   win_length=200, \n",
    "                                   n_mfcc=80,\n",
    "                                   n_mels=80,\n",
    "                                   hop_length=80, \n",
    "                                   window='hamming', \n",
    "                                   fmin=10.0, fmax=4000, \n",
    "                                   trainable_mel=False, \n",
    "                                   trainable_STFT=False,\n",
    "                                   verbose=False, norm=1)\n",
    "\n",
    "def trans3(x):\n",
    "    x = np.squeeze(x)\n",
    "    S = librosa.feature.melspectrogram(x, sr=8000, \n",
    "                                       n_mels=80, n_fft=512,\n",
    "                                       hop_length=80, win_length=200, \n",
    "                                       window='hamming', \n",
    "                                       fmin=10.0, fmax=4000,\n",
    "                                       center=True, pad_mode='reflect', \n",
    "                                       power=2.0, norm='slaney')\n",
    "    S = librosa.power_to_db(S)\n",
    "    mfcc = librosa.feature.mfcc(S=S, sr=8000, n_mfcc=80, norm='ortho')\n",
    "    return np.expand_dims(mfcc, 0)\n",
    "\n",
    "from processing.audio_loader import loadWAV\n",
    "audio_file = \"log_service/audio_thudth1/audio_thudth1/ref_audio/988988883/988988883-2022-03-24-10-31-23.wav\"\n",
    "audio  = np.array(loadWAV(audio_file, 200, evalmode=False))\n",
    "\n",
    "audio_tensor = torch.FloatTensor(audio)\n",
    "\n",
    "out1 = trans1(audio_tensor).detach().cpu().numpy()\n",
    "\n",
    "out2 = trans2(audio_tensor).detach().cpu().numpy()\n",
    "\n",
    "out3 = trans3(audio)\n",
    "\n",
    "print(out1.shape, out2.shape, out3.shape)\n",
    "# np.allclose(out1, out2, rtol=1e-05, atol=1e-08, equal_nan=False)\n",
    "np.testing.assert_allclose(out2, out3, rtol=1e-03, atol=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f75f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "\n",
    "# remap speaker name\n",
    "mapped_name = {}\n",
    "with open('dataset/gan_nhan/name_map_cskh.txt','r') as rf:\n",
    "    lines = [line.replace('\\n', '') for line in rf.readlines()]\n",
    "for line in tqdm(lines):\n",
    "    org_name, dest_name = line.split()\n",
    "    mapped_name.setdefault(dest_name, org_name)\n",
    "    \n",
    "    print(f'mv dataset/train_data/callbot_oslb/wav/{dest_name} dataset/train_data/callbot_oslb/wav/{org_name}')\n",
    "#     subprocess.call(f'mv dataset/train_data/callbot_oslb/wav/{dest_name} dataset/train_data/callbot_oslb/wav/{org_name}', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c98fe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lines_ = []\n",
    "\n",
    "for rg in tqdm(glob.glob(\"dataset/gan_nhan/ban_giao_gan_nhan/data_*\")):\n",
    "    for csv_f in glob.glob(f\"{rg}/*_csv/*.csv\"):     \n",
    "        lines  = []          \n",
    "        with open(csv_f, newline='') as rf:\n",
    "            spamreader = csv.reader(rf, delimiter=',')\n",
    "            next(spamreader, None)\n",
    "            for row in spamreader:\n",
    "                spkID, audio_name, not_ok, gender, regions = row[:5]\n",
    "                spkID = mapped_name[spkID]\n",
    "                lines.append([spkID, audio_name, not_ok, gender, regions]) # spkID audio_name not_ok gender regions\n",
    "                \n",
    "        with open('dataset/gan_nhan/ban_giao_gan_nhan/tonghop.csv', 'w', newline='') as wf:\n",
    "            spamwriter = csv.writer(wf, delimiter=',')\n",
    "            spamwriter.writerow(['audio_path', 'gender', 'region'])\n",
    "            for line in lines:\n",
    "                if str(line[-3]) != '1':\n",
    "                    spamwriter.writerow([os.path.join(line[0], line[1]), line[-2], line[-1]])\n",
    "                lines_.append([os.path.join(line[0], line[1]), line[-2], line[-1]])\n",
    "# len(not_ok_files), len(glob.glob('dataset/ban_giao_gan_nhan/data_*/data_*/data_*/spk*/*.mp3')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a100c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set([line[0].split('/')[0] for line in lines_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390f143",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(os.listdir('dataset/train_data/callbot_oslb/wav/')).intersection(set(os.listdir('dataset/train_data/callbot_raw/wav/')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
