{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14fd88dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\\Namdp5-Personal\\CodeWorkspace\n"
     ]
    }
   ],
   "source": [
    "%cd H:\\Namdp5-Personal\\CodeWorkspace\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b64febc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_to_yaml(overrides):\n",
    "    \"\"\"Convert args to yaml for overrides\"\"\"\n",
    "    yaml_string = \"\"\n",
    "\n",
    "    # Handle '--arg=val' type args\n",
    "    joined_args = \"=\".join(overrides)\n",
    "    split_args = joined_args.split(\"=\")\n",
    "\n",
    "    for arg in split_args:\n",
    "        if arg.startswith(\"--\"):\n",
    "            yaml_string += \"\\n\" + arg[len(\"--\") :] + \":\"\n",
    "        else:\n",
    "            yaml_string += \" \" + arg\n",
    "\n",
    "    return yaml_string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "958da317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperpyyaml import load_hyperpyyaml\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Run a SpeechBrain experiment\")\n",
    "parser.add_argument(\n",
    "        \"param_file\",\n",
    "        type=str,\n",
    "        help=\"A yaml-formatted file using the extended YAML syntax. \"\n",
    "        \"defined by SpeechBrain.\",\n",
    "    )\n",
    "parser.add_argument(\n",
    "    \"--nonfinite_patience\",\n",
    "    type=int,\n",
    "    help=\"Max number of batches per epoch to skip if loss is nonfinite.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--noprogressbar\",\n",
    "    default=None,\n",
    "    action=\"store_true\",\n",
    "    help=\"This flag disables the data loop progressbars.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--ckpt_interval_minutes\",\n",
    "    type=float,\n",
    "    help=\"Amount of time between saving intra-epoch checkpoints \"\n",
    "    \"in minutes. If non-positive, intra-epoch checkpoints are not saved.\",\n",
    ")\n",
    "\n",
    "# SpeakerVerification/SpeakerVerification/backup/config/configuration.yaml\n",
    "run_opts, overrides = parser.parse_known_args(['SpeakerVerification/SpeakerVerification/backup/config/configuration.yaml'])\n",
    "run_opts = {k: v for k, v in vars(run_opts).items() if v is not None}\n",
    "overrides = _convert_to_yaml(overrides)\n",
    "param_file = run_opts[\"param_file\"]\n",
    "with open(param_file) as fin:\n",
    "    hparams = load_hyperpyyaml(fin, overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f88aa7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\\Namdp5-Personal\\CodeWorkspace\\SpeakerVerification\\SpeakerVerification\n"
     ]
    }
   ],
   "source": [
    "%cd SpeakerVerification/SpeakerVerification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18917b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n",
      "PyTorch Version: 1.11.0+cpu\n",
      "Number of GPUs: 0\n",
      "Namespace(audio_spec={'sample_rate': 16000, 'sentence_len': 3.0, 'win_len': 0.025, 'hop_len': 0.01}, augment=False, augment_options={'augment_paths': {'musan': 'dataset/augment_data//musan_split', 'noise_vad': 'dataset/augment_data//voice_vad', 'rirs': 'dataset/augment_data//RIRS_NOISES'}, 'augment_chain': ['env_corrupt', 'time_domain', 'spec_domain'], 'noise_sets': ['noise', 'speech', 'music', 'noise_vad', 'noise_rirs'], 'noise_proportion': [0.1, 0.1, 0.1, 0.2, 0.5], 'noise_snr': {'noise': [0, 5], 'speech': [3, 20], 'music': [5, 15], 'noise_vad': [0, 15], 'noise_rirs': [0, 15]}, 'noise_samples': {'noise': [1, 1], 'speech': [3, 7], 'music': [1, 1], 'noise_vad': [1, 1], 'noise_rirs': [1, 1]}}, augment_time_domain={'volume': 6, 'speed': [0.95, 1.05], 'pitch': [-0.5, 0.5], 'proportion': [0.25, 0.25, 0.25], 'combined': False}, base_lr=1e-08, batch_size=32, callbacks={'name': 'steplr', 'base_lr': 1e-08, 'max_lr': 0.001, 'step_size': 65000}, ckpt_interval_minutes=15, classifier={'input_size': 512, 'out_neurons': 7724}, cohort_size=23172, config='backup/config/configuration.yaml', criterion={'name': 'ARmSoftmax', 'margin': 0.2, 'scale': 30, 'hard_prob': 0.5, 'hard_rank': 0.5, 'scale_pos': 2.0, 'scale_neg': 50.0}, data_folder='dataset/', dataloader_options={'batch_size': 32, 'shuffle': True, 'num_workers': 2, 'max_seg_per_spk': 1000, 'nPerSpeaker': 2}, dcf={'dcf_p_target': 0.05, 'dcf_c_miss': 1, 'dcf_c_fa': 1}, device='cuda', distributed=True, do_export=False, do_infer=False, do_train=True, early_stopping=False, es_patience=15, eval=False, features='raw', initial_model_infer='backup/Raw_ECAPA/model/best_state.model', lib='nnaudio', log_test_files={'ref': 'test_path.txt', 'com': \"test_path.txt.replace('.txt', '_results.txt')\"}, lr=0.001, max_lr=0.001, mixedprec=False, model={'name': 'Raw_ECAPA', 'nOut': 512}, nClasses=7724, nDataLoaderThread=2, n_mels=80, n_mfcc=80, noise_folder='dataset/augment_data/', num_eval=10, number_of_epochs=10, optimizer={'name': 'AdaBelief', 'weight_decay': 2e-05, 'lr_decay': 0.95}, output_folder='backup/1001', port='8888', predict=False, prepare='embed', pretrained={'use': True, 'path': 'backup/Raw_ECAPA/AAmSoftmax/model/best_state.pt'}, random_chunk=True, save_folder='backup/1001/save', save_model_last=True, scoring_mode='cosine', seed=1811, shuffle=True, skip_prep=True, step_size=65000, test=False, test_interval=-1, test_threshold=0.5, train_annotation='backup/1001/save/metadata/train.csv', train_log='backup/1001/train_log.txt', valid_annotation='backup/1001/save/metadata/dev.csv', verification_file='test_path.txt')\n"
     ]
    }
   ],
   "source": [
    "!python main.py --do_train --config backup/config/configuration.yaml --seed 1811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f49db-9a5c-45af-b247-55a3aabef9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def convert_audio(src):\n",
    "    \"\"\"Convert audio format and samplerate to target\"\"\"\n",
    "    ext='wav'\n",
    "    sample_rate=8000\n",
    "    channels=1\n",
    "    codec='pcm_s16le'\n",
    "    dst=None\n",
    "    try:\n",
    "        org_format = src.split('.')[-1].strip()\n",
    "        if ext != org_format:\n",
    "            audio = AudioSegment.from_file(src)\n",
    "            # export file as new format\n",
    "            src = src.replace(org_format, ext)\n",
    "            audio.export(src, format=ext)\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "    try:\n",
    "        sound = AudioSegment.from_file(src, format='wav')\n",
    "        sound = sound.set_frame_rate(sample_rate)\n",
    "        sound = sound.set_channels(channels)\n",
    "\n",
    "        dst = src if not dst else dst\n",
    "\n",
    "        sound.export(dst, format='wav')\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "audio_list = glob.glob(\"dataset/**/*.wav\", recursive=True)\n",
    "p = Pool(processes=12)\n",
    "p.map(convert_audio, audio_list)\n",
    "p.join()\n",
    "p.close()\n",
    "print('----')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
