device: "cpu"
seed: 1001
distributed: False
distributed_backend: nccl
mixedprec: False

# Directories
output_folder: !ref backup/<seed>
save_folder: !ref <output_folder>/save
train_log: !ref <output_folder>/train_log.txt

## Paths
skip_prep: True
data_folder: dataset/train_data/zalo_ai
train_annotation: !ref <save_folder>/metadata/train.txt
valid_annotation: !ref <save_folder>/metadata/dev.txt
# train_annotation: dataset/train_data/sample/metadata/train_sample.txt
# valid_annotation: dataset/train_data/sample/metadata/val_sample.txt

verification_file: test_path.txt
noise_folder: dataset/augment_data/

ckpt_interval_minutes: 15 # save checkpoint every N min, -1 to turn off
save_model_last: True

# Training parameters
number_of_epochs: 10 # max_epoch
batch_size: 32 # batch_size
lr: 0.001
base_lr: 0.00000001
max_lr: !ref <lr>
step_size: 65000
shuffle: False
random_chunk: True

# Audio parameters
audio_spec:
  sample_rate: 16000 # sample_rate
  channels: 1
  sentence_len: 2.0 # seconds max_frames
  win_len: 0.025
  hop_len: 0.01 # Hop length is the length of the non-intersecting portion of window length

# Feature parameters
n_mfcc: 80
n_mels: 80
features: raw
lib: nnaudio

# Number of speakers
nClasses: 120 #1211 for vox1  # 5994 for vox2, 7205 for vox1+vox2

# dataloader_options
dataloader_options:
  batch_size: !ref <batch_size>
  shuffle: !ref <shuffle>
  num_workers: 2
  max_seg_per_spk: 1000
  nPerSpeaker: 2
  split_ratio: -1

# # Augment options
augment: False
augment_options:
  augment_paths:
    musan: !ref <noise_folder>/musan_split
    noise_vad: !ref <noise_folder>/voice_vad
    rirs: !ref <noise_folder>/RIRS_NOISES
  augment_chain: ["env_corrupt", "time_domain", "spec_domain"]
  noise_sets: ["noise", "speech", "music", "noise_vad", "noise_rirs"]
  noise_proportion: [0.1, 0.1, 0.1, 0.2, 0.5]
  noise_snr:
    noise: [0, 5]
    speech: [3, 20]
    music: [5, 15]
    noise_vad: [0, 15]
    noise_rirs: [0, 15]
  noise_samples:
    noise: [1, 1]
    speech: [3, 7]
    music: [1, 1]
    noise_vad: [1, 1]
    noise_rirs: [1, 1]
  augment_time_domain:
    volume: 6
    speed: [0.95, 1.05]
    pitch: [-0.5, 0.5]
    proportion: [0.25, 0.25, 0.25]
    combined: False

## Model definition
model:
  name: Raw_ECAPA
  nOut: 512 #lin neurons

classifier:
  input_size: !ref <model[nOut]>
  out_neurons: !ref <nClasses>

## criterion
criterion:
  name: ARmSoftmax
  margin: 0.2
  scale: 30
  hard_prob: 0.5
  hard_rank: 0.5
  scale_pos: 2.0
  scale_neg: 50.0

## optimizer
optimizer:
  name: AdaBelief
  weight_decay: 0.00002
  lr_decay: 0.95

## callbacks
callbacks:
  name: steplr
  base_lr: !ref <base_lr>
  max_lr: !ref <max_lr>
  step_size: !ref <step_size>

early_stopping: False
es_patience: 15

# Using pretrain
pretrained:
  use: True
  path: backup/Raw_ECAPA/AAmSoftmax/model/best_state.pt

## testing
test_interval: -1
dcf:
  dcf_p_target: 0.05
  dcf_c_miss: 1
  dcf_c_fa: 1
num_eval: 10
prepare: embed # 'embed / cohorts'
cohort_size: !ref <nClasses> * 3
test_threshold: 0.5
scoring_mode: cosine
log_test_files:
  ref: !ref <verification_file>
  com: !ref <verification_file>.replace('.txt', '_results.txt')
# initial_model test:
initial_model_infer: backup/Raw_ECAPA/model/best_state.model
